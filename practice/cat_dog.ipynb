{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1m6DC2IrRSCwQMHRdgKSuXqokMxZSuzkf",
      "authorship_tag": "ABX9TyPguYBcL+2pSyngU6tEFozS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/G-who0212/video_image_processing/blob/main/practice/cat_dog.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQhd3ZRlrFvY",
        "outputId": "b1c476a9-cdc6-44ae-e85a-adde902a4da9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /content/kaggle.json'\n",
            "Downloading dogs-vs-cats-redux-kernels-edition.zip to /content\n",
            " 99% 803M/814M [00:05<00:00, 123MB/s]\n",
            "100% 814M/814M [00:06<00:00, 142MB/s]\n"
          ]
        }
      ],
      "source": [
        "# 이미지 데이터를 코랩에서 다운받는 방법\n",
        "# 1. 왼쪽의 파일트리에다가 업로드 하던가 -> 시간이 너무 오래 걸림..\n",
        "# 2. 직접 다운받는 코드를 짜던가\n",
        "\n",
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = '/content/'\n",
        "\n",
        "!kaggle competitions download -c dogs-vs-cats-redux-kernels-edition"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/dogs-vs-cats-redux-kernels-edition.zip -d ."
      ],
      "metadata": {
        "id": "Nl_YcWcLyCwz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q train.zip -d ."
      ],
      "metadata": {
        "id": "2I7eIV34yfMJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print( len(os.listdir('/content/train/')))\n",
        "#os.listdir('폴더') -> 폴더 안의 파일들을 리스트 안에 전부 담는다. [파일명1, 파일명2, 파일명3,...]\n",
        "\n",
        "os.mkdir('/content/dataset')\n",
        "os.mkdir('/content/dataset/cat')\n",
        "os.mkdir('/content/dataset/dog')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zgv7G6ACyzxN",
        "outputId": "70db3ed5-2c75-4f88-ad58-09e527135fb5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#이미지를 숫자로 변환해야 함\n",
        "# 1. opencv 라이브러리로 이미지 숫자화하기\n",
        "# 2. tf.keras 이용하여 한큐에 처리하기(tf.keras.preprocessing.image_dataset_from_directory()) -> 이거로 하겠음\n",
        "import tensorflow as tf\n",
        "import shutil # 파일의 위치를 옮길 수 있도록 도와줌\n",
        "\n",
        "# dataset이라는 폴더를 만들고 cat, dog이라는 폴더를 만들었다.\n",
        "\n",
        "for i in os.listdir('/content/train/'): # [cat1.jpg, cat2.jpg, ... dog1.jpg, dog2.jpg...]\n",
        "  if 'cat' in i: # 이름에 cat이 들어있으면, cat폴더로 이동\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/cat/' + i)\n",
        "  if 'dog' in i: # 이름에 dog이 들어있으면, dog폴더로 이동\n",
        "    shutil.copyfile('/content/train/' + i, '/content/dataset/dog/' + i)\n",
        "\n",
        "# tf.keras.preprocessing.image_dataset_from_directory()\n"
      ],
      "metadata": {
        "id": "3Uy6Qw7ozPA2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# %rm -rf dataset"
      ],
      "metadata": {
        "id": "tApV0Z8D8Uqu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  '/content/dataset/',\n",
        "  image_size=(64,64), # 모든 데이터들을 64*64로 만든다. -> 전처리\n",
        "  batch_size=32, # epoch(반복)를 돌릴 때, 이미지 2만장을 한번에 넣지 않고, batch 숫자만큼만 넣겠다는 뜻 (한번에 하지 않고 나눠서 넣겠다.)\n",
        "  subset='training', # training의 이름을 가졌음 -> 데이터 셋의 80%를 가져감\n",
        "  validation_split=0.2, # 20%의 데이터를 validation_data_set으로 쪼갠다.\n",
        "  seed=1234\n",
        ") # 폴더내의 이미지들을 바로 적용 가능한 dataset으로 만들어줌\n",
        "\n",
        "# train_ds에는 -> ( (xxxxxxxxx[32개]), (yyyyyyyyy[32개])) 형태의 데이터가 저장된다.\n",
        "\n",
        "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "  '/content/dataset/',\n",
        "  image_size=(64,64), \n",
        "  batch_size=32, \n",
        "  subset='validation', # validation의 이름을 가졌음 -> 데이터 셋의 20%를 가져감\n",
        "  validation_split=0.2,\n",
        "  seed=1234\n",
        ") \n",
        "\n",
        "print(train_ds) # 32개씩 들어있는 batch들의 모음\n",
        "\n",
        "def preprocessFunc(i, ans):\n",
        "  i = tf.cast(i/255.0, tf.float32)\n",
        "  return i, ans\n",
        "\n",
        "train_ds = train_ds.map(preprocessFunc) # map함수 -> train_ds 데이터에 전부 () 안의 함수를 적용시킴\n",
        "val_ds = val_ds.map(preprocessFunc)\n",
        "\n",
        "# import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "# for i, ans in train_ds.take(1): # train_ds의 32개씩 들어있는 batch들에서 하나를 뽑아옴\n",
        "#   print(i) # i -> shape=(32, 64, 64, 3)의 데이터 셋\n",
        "#   print(ans) # ans -> shape=(32,) / 32개의 0 또는 1 로 구성된 데이터 셋\n",
        "#   plt.imshow(i[0].numpy().astype('uint8')) # tensor를 numpy로 변환 / matplotlib는 numpy에서 작동하나봄\n",
        "#   plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s1_AQUAD2F-Q",
        "outputId": "30a6ee72-45fc-4a3e-a4cc-d5a4e256f439"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 25000 files belonging to 2 classes.\n",
            "Using 20000 files for training.\n",
            "Found 25000 files belonging to 2 classes.\n",
            "Using 5000 files for validation.\n",
            "<BatchDataset element_spec=(TensorSpec(shape=(None, 64, 64, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None,), dtype=tf.int32, name=None))>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.Sequential([\n",
        "    tf.keras.layers.experimental.preprocessing.RandomFlip('horizontal', input_shape=(64,64,3)),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n",
        "    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n",
        "\n",
        "    tf.keras.layers.Conv2D(32, (3,3), padding=\"same\", activation='relu', input_shape=(64,64,3)),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), padding=\"same\", activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Dropout(0.2), # overfitting 완화기능 -> 윗레이어 노드의 20%의 값을 0으로 만듬\n",
        "    tf.keras.layers.Conv2D(128, (3,3), padding=\"same\", activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D((2,2)),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "    tf.keras.layers.Dropout(0.2),\n",
        "    tf.keras.layers.Dense(1, activation=\"sigmoid\") # 0~1사이 값이 출력 됨\n",
        "])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss=\"binary_crossentropy\", metrics=['accuracy'])\n",
        "model.fit(train_ds, validation_data=(val_ds), epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aiUuebJAjl7",
        "outputId": "dcf8cff8-a3b4-4544-9a6d-a6b6102a59fd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " random_flip (RandomFlip)    (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " random_rotation (RandomRota  (None, 64, 64, 3)        0         \n",
            " tion)                                                           \n",
            "                                                                 \n",
            " random_zoom (RandomZoom)    (None, 64, 64, 3)         0         \n",
            "                                                                 \n",
            " conv2d (Conv2D)             (None, 64, 64, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 32, 32, 32)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 32, 32, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 16, 16, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 16, 16, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 128)               1048704   \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 128)               0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 129       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,142,081\n",
            "Trainable params: 1,142,081\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/5\n",
            "625/625 [==============================] - 45s 56ms/step - loss: 0.6509 - accuracy: 0.6202 - val_loss: 0.7335 - val_accuracy: 0.6124\n",
            "Epoch 2/5\n",
            "625/625 [==============================] - 38s 60ms/step - loss: 0.5631 - accuracy: 0.7113 - val_loss: 0.5210 - val_accuracy: 0.7380\n",
            "Epoch 3/5\n",
            "625/625 [==============================] - 36s 57ms/step - loss: 0.5220 - accuracy: 0.7419 - val_loss: 0.5609 - val_accuracy: 0.7098\n",
            "Epoch 4/5\n",
            "625/625 [==============================] - 33s 53ms/step - loss: 0.4978 - accuracy: 0.7646 - val_loss: 0.5168 - val_accuracy: 0.7486\n",
            "Epoch 5/5\n",
            "625/625 [==============================] - 36s 58ms/step - loss: 0.4739 - accuracy: 0.7769 - val_loss: 0.4569 - val_accuracy: 0.7906\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f354e24dfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lmCGViXBFXx4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}